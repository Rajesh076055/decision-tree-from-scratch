{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:56.920528Z","iopub.status.busy":"2023-03-01T07:47:56.919598Z","iopub.status.idle":"2023-03-01T07:47:58.225490Z","shell.execute_reply":"2023-03-01T07:47:58.224314Z","shell.execute_reply.started":"2023-03-01T07:47:56.920469Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["modules imported successfully.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from sklearn.feature_extraction.text import CountVectorizer\n","import string\n","\n","print(\"modules imported successfully.\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.228458Z","iopub.status.busy":"2023-03-01T07:47:58.227848Z","iopub.status.idle":"2023-03-01T07:47:58.277077Z","shell.execute_reply":"2023-03-01T07:47:58.276145Z","shell.execute_reply.started":"2023-03-01T07:47:58.228418Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Category                                            Message\n","0      ham  Go until jurong point, crazy.. Available only ...\n","1      ham                      Ok lar... Joking wif u oni...\n","2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3      ham  U dun say so early hor... U c already then say...\n","4      ham  Nah I don't think he goes to usf, he lives aro..."]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv(\"/kaggle/input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\")\n","data.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.280325Z","iopub.status.busy":"2023-03-01T07:47:58.279697Z","iopub.status.idle":"2023-03-01T07:47:58.284538Z","shell.execute_reply":"2023-03-01T07:47:58.283342Z","shell.execute_reply.started":"2023-03-01T07:47:58.280288Z"},"trusted":true},"outputs":[],"source":["# data = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\n","# data.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.288082Z","iopub.status.busy":"2023-03-01T07:47:58.287687Z","iopub.status.idle":"2023-03-01T07:47:58.294875Z","shell.execute_reply":"2023-03-01T07:47:58.293898Z","shell.execute_reply.started":"2023-03-01T07:47:58.288045Z"},"trusted":true},"outputs":[],"source":["# data = data.rename(columns ={\"v1\":\"Category\", \"v2\":\"Message\"})\n","# data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.297600Z","iopub.status.busy":"2023-03-01T07:47:58.297200Z","iopub.status.idle":"2023-03-01T07:47:58.304334Z","shell.execute_reply":"2023-03-01T07:47:58.303388Z","shell.execute_reply.started":"2023-03-01T07:47:58.297574Z"},"trusted":true},"outputs":[],"source":["# data[\"Category\"]=data[\"Category\"].replace({'spam':1,'ham':0})\n","# data.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.306505Z","iopub.status.busy":"2023-03-01T07:47:58.306100Z","iopub.status.idle":"2023-03-01T07:47:58.417900Z","shell.execute_reply":"2023-03-01T07:47:58.416822Z","shell.execute_reply.started":"2023-03-01T07:47:58.306471Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>go until jurong point crazy available only in ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>ok lar joking wif u oni</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>free entry in  a wkly comp to win fa cup final...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>u dun say so early hor u c already then say</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>nah i dont think he goes to usf he lives aroun...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Category                                            Message\n","0      ham  go until jurong point crazy available only in ...\n","1      ham                            ok lar joking wif u oni\n","2     spam  free entry in  a wkly comp to win fa cup final...\n","3      ham        u dun say so early hor u c already then say\n","4      ham  nah i dont think he goes to usf he lives aroun..."]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["def clean_text(Message):\n","    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n","    and remove words containing numbers.'''\n","    Message = Message.lower()\n","    Message = re.sub('\\[.*?\\]', '', Message)\n","    Message = re.sub('https?://\\S+|www\\.\\S+', '', Message)\n","    Message = re.sub('<.*?>+', '', Message)\n","    Message = re.sub('[%s]' % re.escape(string.punctuation), '', Message)\n","    Message = re.sub('\\n', '', Message)\n","    Message = re.sub('\\w*\\d\\w*', '', Message)\n","    # Message = Message.split()\n","    # ps = PorterStemmer()\n","    # Message = [ps.stem(word) for word in Message if not word in set(stopwords.words('english'))]\n","    # Message = ' '.join(Message)\n","    return Message\n","\n","data['Message']=data['Message'].apply(clean_text)\n","\n","data.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.419909Z","iopub.status.busy":"2023-03-01T07:47:58.419076Z","iopub.status.idle":"2023-03-01T07:47:58.428788Z","shell.execute_reply":"2023-03-01T07:47:58.427372Z","shell.execute_reply.started":"2023-03-01T07:47:58.419872Z"},"trusted":true},"outputs":[],"source":["x=data['Message']\n","y=data['Category']\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.431371Z","iopub.status.busy":"2023-03-01T07:47:58.430372Z","iopub.status.idle":"2023-03-01T07:47:58.550068Z","shell.execute_reply":"2023-03-01T07:47:58.548738Z","shell.execute_reply.started":"2023-03-01T07:47:58.431332Z"},"trusted":true},"outputs":[{"data":{"text/plain":["CountVectorizer(max_features=500)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["cv = CountVectorizer(max_features = 500)\n","cv.fit(x_train)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.553547Z","iopub.status.busy":"2023-03-01T07:47:58.553253Z","iopub.status.idle":"2023-03-01T07:47:58.612614Z","shell.execute_reply":"2023-03-01T07:47:58.611705Z","shell.execute_reply.started":"2023-03-01T07:47:58.553520Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<4179x500 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 36976 stored elements in Compressed Sparse Row format>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["X_train_cv = cv.transform(x_train)\n","X_train_cv"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.617795Z","iopub.status.busy":"2023-03-01T07:47:58.616939Z","iopub.status.idle":"2023-03-01T07:47:58.642249Z","shell.execute_reply":"2023-03-01T07:47:58.641190Z","shell.execute_reply.started":"2023-03-01T07:47:58.617757Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<1393x500 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 11853 stored elements in Compressed Sparse Row format>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["X_test_cv = cv.transform(x_test)\n","X_test_cv"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.644405Z","iopub.status.busy":"2023-03-01T07:47:58.643959Z","iopub.status.idle":"2023-03-01T07:47:58.648766Z","shell.execute_reply":"2023-03-01T07:47:58.647703Z","shell.execute_reply.started":"2023-03-01T07:47:58.644369Z"},"trusted":true},"outputs":[],"source":["# vectorization = TfidfVectorizer()\n","# xv_train = vectorization.fit_transform(x_train)\n","# xv_test = vectorization.transform(x_test)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.650979Z","iopub.status.busy":"2023-03-01T07:47:58.650273Z","iopub.status.idle":"2023-03-01T07:47:58.659465Z","shell.execute_reply":"2023-03-01T07:47:58.658763Z","shell.execute_reply.started":"2023-03-01T07:47:58.650942Z"},"trusted":true},"outputs":[],"source":["class Node():\n","    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n","        \n","        # for decision node\n","        self.feature_index=feature_index\n","        self.threshold=threshold\n","        self.left=left\n","        self.right=right\n","        self.info_gain=info_gain\n","        \n","        # for leaf node\n","        self.value=value\n","        "]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.661616Z","iopub.status.busy":"2023-03-01T07:47:58.660942Z","iopub.status.idle":"2023-03-01T07:47:58.685844Z","shell.execute_reply":"2023-03-01T07:47:58.684858Z","shell.execute_reply.started":"2023-03-01T07:47:58.661580Z"},"trusted":true},"outputs":[],"source":["class DecisionTreeClassifier():\n","    def __init__(self, min_samples_split=2, max_depth=2):\n","        ''' constructor '''\n","        \n","        # initialize the root of the tree \n","        self.root = None\n","        \n","        # stopping conditions\n","        self.min_samples_split = min_samples_split\n","        self.max_depth = max_depth\n","        \n","    def build_tree(self, dataset, curr_depth=0):\n","        ''' recursive function to build the tree ''' \n","        \n","        X, Y = dataset[:,:-1], dataset[:,-1]\n","        num_samples, num_features = np.shape(X)\n","\n","        \n","        # split until stopping conditions are met\n","        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n","            # find the best split\n","\n","            best_split = self.get_best_split(dataset, num_samples, num_features)\n","            \n","\n","            # check if information gain is positive\n","            if best_split[\"info_gain\"]>0:\n","                # recur left\n","                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n","                # recur right\n","                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n","   \n","                \n","                # return decision node\n","                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n","                            left_subtree, right_subtree, best_split[\"info_gain\"])\n","                \n","                \n","        \n","        # compute leaf node\n","        leaf_value = self.calculate_leaf_value(Y)\n","\n","        # return leaf node\n","        return Node(value=leaf_value)\n","    \n","    def get_best_split(self, dataset, num_samples, num_features):\n","\n","        ''' function to find the best split '''\n"," \n","        # dictionary to store the best split\n","        best_split = {}\n","        max_info_gain = -float(\"inf\")\n","        \n","      \n","\n","        # loop over all the features\n","        for feature_index in range(num_features):\n","        \n","            feature_values = dataset[:, feature_index]\n","         \n","            possible_thresholds = np.unique(feature_values)\n","\n","            # loop over all the feature values present in the data\n","            for threshold in possible_thresholds:\n","              \n","                # get current split\n","                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n","                # check if childs are not null\n","                if len(dataset_left)>0 and len(dataset_right)>0:\n","             \n","                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n","                    # compute information gain\n","                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n","                    # update the best split if needed\n","                    if curr_info_gain>max_info_gain:\n","                 \n","                        best_split[\"feature_index\"] = feature_index\n","                        best_split[\"threshold\"] = threshold\n","                        best_split[\"dataset_left\"] = dataset_left\n","                        best_split[\"dataset_right\"] = dataset_right\n","                        best_split[\"info_gain\"] = curr_info_gain\n","                        max_info_gain = curr_info_gain\n","                        \n","        # return best split\n","        return best_split\n"," \n","    def split(self, dataset, feature_index, threshold):\n","        ''' function to split the data '''\n","        \n","        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n","        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n","        return dataset_left, dataset_right\n","    \n","    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n","        ''' function to compute information gain '''\n","        \n","        weight_l = len(l_child) / len(parent)\n","        weight_r = len(r_child) / len(parent)\n","        if mode==\"gini\":\n","            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n","        else:\n","            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n","        return gain\n","    \n","    def entropy(self, y):\n","        ''' function to compute entropy '''\n","        \n","        class_labels = np.unique(y)\n","        entropy = 0\n","        for cls in class_labels:\n","            p_cls = len(y[y == cls]) / len(y)\n","            entropy += -p_cls * np.log2(p_cls)\n","        return entropy\n","    \n","    def gini_index(self, y):\n","        ''' function to compute gini index '''\n","        \n","        class_labels = np.unique(y)\n","        gini = 0\n","        for cls in class_labels:\n","            p_cls = len(y[y == cls]) / len(y)\n","            gini += p_cls**2\n","        return 1 - gini\n","        \n","    def calculate_leaf_value(self, Y):\n","        ''' function to compute leaf node '''\n","        \n","        Y = list(Y)\n","        return max(Y, key=Y.count)\n","    \n","    def print_tree(self, tree=None, indent=\" \"):\n","        ''' function to print the tree '''\n","        \n","        if not tree:\n","            tree = self.root\n","\n","        if tree.value is not None:\n","            print(tree.value)\n","\n","        else:\n","            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n","            print(\"%sleft:\" % (indent), end=\"\")\n","            self.print_tree(tree.left, indent + indent)\n","            print(\"%sright:\" % (indent), end=\"\")\n","            self.print_tree(tree.right, indent + indent)\n","    \n","    def fit(self, X, Y):\n","        ''' function to train the tree '''\n","        \n","        dataset = np.concatenate((X, Y), axis=1)\n","        self.root = self.build_tree(dataset)\n","    \n","    def predict(self, X):\n","        ''' function to predict new dataset '''\n","        \n","        preditions = [self.make_prediction(x, self.root) for x in X]\n","        return preditions\n","    \n","    def make_prediction(self, x, tree):\n","        ''' function to predict a single data point '''\n","        \n","        if tree.value!=None: return tree.value\n","        feature_val = x[tree.feature_index]\n","        if feature_val<=tree.threshold:\n","            return self.make_prediction(x, tree.left)\n","        else:\n","            return self.make_prediction(x, tree.right)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.687488Z","iopub.status.busy":"2023-03-01T07:47:58.687083Z","iopub.status.idle":"2023-03-01T07:47:58.698912Z","shell.execute_reply":"2023-03-01T07:47:58.698002Z","shell.execute_reply.started":"2023-03-01T07:47:58.687454Z"},"trusted":true},"outputs":[],"source":["# from sklearn.tree import DecisionTreeClassifier"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.700822Z","iopub.status.busy":"2023-03-01T07:47:58.700403Z","iopub.status.idle":"2023-03-01T07:47:58.719588Z","shell.execute_reply":"2023-03-01T07:47:58.718482Z","shell.execute_reply.started":"2023-03-01T07:47:58.700786Z"},"trusted":true},"outputs":[],"source":["X_train_cv=X_train_cv.toarray()\n","y_train=y_train.to_numpy().reshape(-1,1)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:47:58.722290Z","iopub.status.busy":"2023-03-01T07:47:58.721642Z","iopub.status.idle":"2023-03-01T07:52:37.640709Z","shell.execute_reply":"2023-03-01T07:52:37.639585Z","shell.execute_reply.started":"2023-03-01T07:47:58.722255Z"},"trusted":true},"outputs":[],"source":["classifier = DecisionTreeClassifier(min_samples_split=100, max_depth=10)\n","classifier.fit(X_train_cv,y_train)\n","# classifier.print_tree() #this is commented because printing the tree takes too much memory and the system collapses."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:52:37.642805Z","iopub.status.busy":"2023-03-01T07:52:37.642386Z","iopub.status.idle":"2023-03-01T07:52:37.657478Z","shell.execute_reply":"2023-03-01T07:52:37.656433Z","shell.execute_reply.started":"2023-03-01T07:52:37.642766Z"},"trusted":true},"outputs":[],"source":["X_test_cv=X_test_cv.toarray()\n","y_test=y_test.to_numpy().reshape(-1,1)\n","\n","Y_pred = classifier.predict(X_test_cv) "]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:52:37.659818Z","iopub.status.busy":"2023-03-01T07:52:37.659337Z","iopub.status.idle":"2023-03-01T07:52:37.701556Z","shell.execute_reply":"2023-03-01T07:52:37.700468Z","shell.execute_reply.started":"2023-03-01T07:52:37.659776Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy score:  0.9454414931801867\n","recall score:  0.8395547883626424\n","precision score:  0.909942472593075\n","f1 score:  0.8700572460993117\n","confusiion matrix:  [[1189   20]\n"," [  56  128]]\n"]}],"source":["from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score,confusion_matrix,roc_curve,RocCurveDisplay, auc\n","\n","print(\"accuracy score: \",accuracy_score(y_test, Y_pred))\n","print(\"recall score: \", recall_score(y_test, Y_pred, average='macro'))\n","print(\"precision score: \", precision_score(y_test, Y_pred, average='macro'))\n","print(\"f1 score: \", f1_score(y_test, Y_pred, average='macro'))\n","print(\"confusiion matrix: \",confusion_matrix(y_test, Y_pred))"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:52:37.703468Z","iopub.status.busy":"2023-03-01T07:52:37.703126Z","iopub.status.idle":"2023-03-01T07:52:37.708073Z","shell.execute_reply":"2023-03-01T07:52:37.706798Z","shell.execute_reply.started":"2023-03-01T07:52:37.703433Z"},"trusted":true},"outputs":[],"source":["# print(\"The ROC Curve is as: \")\n","# RocCurveDisplay.from_estimator(classifier,X_test_cv,y_test)  #roc curve is difficult to get with custom model. so this is commented out."]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:52:37.710706Z","iopub.status.busy":"2023-03-01T07:52:37.709805Z","iopub.status.idle":"2023-03-01T07:52:37.718879Z","shell.execute_reply":"2023-03-01T07:52:37.717885Z","shell.execute_reply.started":"2023-03-01T07:52:37.710646Z"},"trusted":true},"outputs":[],"source":["# your custom input. uncomment to check.\n","\n","# test=input(\"enter text: \")\n","# test=[test]\n","# test = cv.transform(test)\n","# test=test.toarray()\n","# print(classifier.predict(test))"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:52:37.720925Z","iopub.status.busy":"2023-03-01T07:52:37.720244Z","iopub.status.idle":"2023-03-01T07:52:37.730152Z","shell.execute_reply":"2023-03-01T07:52:37.728971Z","shell.execute_reply.started":"2023-03-01T07:52:37.720884Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['spam']\n"]}],"source":["# test=input(\"enter text: \")\n","test=\"you have won a lottery\"\n","test=[test]\n","test = cv.transform(test)\n","test=test.toarray()\n","print(classifier.predict(test))"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:52:37.731885Z","iopub.status.busy":"2023-03-01T07:52:37.731444Z","iopub.status.idle":"2023-03-01T07:52:37.740342Z","shell.execute_reply":"2023-03-01T07:52:37.739227Z","shell.execute_reply.started":"2023-03-01T07:52:37.731846Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['spam']\n"]}],"source":["# test=input(\"enter text: \")\n","test=\"you have won a vacation trip\"\n","test=[test]\n","test = cv.transform(test)\n","test=test.toarray()\n","print(classifier.predict(test))"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:52:37.742474Z","iopub.status.busy":"2023-03-01T07:52:37.741751Z","iopub.status.idle":"2023-03-01T07:52:37.748049Z","shell.execute_reply":"2023-03-01T07:52:37.747045Z","shell.execute_reply.started":"2023-03-01T07:52:37.742439Z"},"trusted":true},"outputs":[],"source":["# here, 1 means spam and 0 means ham. This was renamed in upper cells."]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-03-01T07:52:37.750586Z","iopub.status.busy":"2023-03-01T07:52:37.749532Z","iopub.status.idle":"2023-03-01T07:52:37.756397Z","shell.execute_reply":"2023-03-01T07:52:37.755711Z","shell.execute_reply.started":"2023-03-01T07:52:37.750548Z"},"trusted":true},"outputs":[],"source":["# you have won a lottery\n","# you have won a vacation trip"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"vscode":{"interpreter":{"hash":"b8714cde6903272b7ca4292882db5cfcaa901f73da86e8047c98a3d067e8ffa3"}}},"nbformat":4,"nbformat_minor":4}
